{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing @UnfareNYC Tweets\n",
    "## CSE184 Final Project Fall 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries and set matplotlib to be inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import twitter\n",
    "import nltk\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#t = twitter(auth=OAuth('144353594-pUtB5UxLeZHwZxJH4vPtFQMXAvgyQKTyvDanafog','TvGH6dRf2J0PTKgBiSwWJ022j25PNBBaYUZQYWML1bDok','0ift2jAgEYQrWs8OP1f9TjRQ1','qq9jNTaS3cG9wVc2Hxij3M0GuhAy72wNzFnBc9y1ejp2xh5dg4'))\n",
    "#pythonTweets = t.search.tweets(q = \"#python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the tweets from @unfarenys and store them in data frame \"tweetsdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>user</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1197272944235483137</td>\n",
       "      <td>unfarenyc</td>\n",
       "      <td>Wed Nov 20 21:58:08 +0000 2019</td>\n",
       "      <td>RT @Hurowittty: @unfarenyc 4 cops ticketing at...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1197264398886350850</td>\n",
       "      <td>unfarenyc</td>\n",
       "      <td>Wed Nov 20 21:24:11 +0000 2019</td>\n",
       "      <td>RT @ironmonopoly: Cops hiding in 42nd/PABT ACE...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1197262875410288643</td>\n",
       "      <td>unfarenyc</td>\n",
       "      <td>Wed Nov 20 21:18:08 +0000 2019</td>\n",
       "      <td>4 cops in uniform by the L train entrance at U...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1197254191384842241</td>\n",
       "      <td>unfarenyc</td>\n",
       "      <td>Wed Nov 20 20:43:37 +0000 2019</td>\n",
       "      <td>3 uniformed cops at 57st/7th ave Q/N/R/W stati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1197251190075080709</td>\n",
       "      <td>unfarenyc</td>\n",
       "      <td>Wed Nov 20 20:31:42 +0000 2019</td>\n",
       "      <td>2 cops standing at the top of the stairs of th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>1195812272792330249</td>\n",
       "      <td>unfarenyc</td>\n",
       "      <td>Sat Nov 16 21:13:57 +0000 2019</td>\n",
       "      <td>3 cops by the turnstiles at the main entrance ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>1195808664285790210</td>\n",
       "      <td>unfarenyc</td>\n",
       "      <td>Sat Nov 16 20:59:37 +0000 2019</td>\n",
       "      <td>Three cops at Grand Central turnstiles near 7 ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>1195756090966892545</td>\n",
       "      <td>unfarenyc</td>\n",
       "      <td>Sat Nov 16 17:30:42 +0000 2019</td>\n",
       "      <td>3 cops at 47-50st Rockefeller center 50th st e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>1195755807465447426</td>\n",
       "      <td>unfarenyc</td>\n",
       "      <td>Sat Nov 16 17:29:35 +0000 2019</td>\n",
       "      <td>RT @cabbage_rat: Blurry pic, but two cops on t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>1195732058812735489</td>\n",
       "      <td>unfarenyc</td>\n",
       "      <td>Sat Nov 16 15:55:13 +0000 2019</td>\n",
       "      <td>Uniformed cops seen giving tickets last seen o...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ID       user                      created_at  \\\n",
       "0    1197272944235483137  unfarenyc  Wed Nov 20 21:58:08 +0000 2019   \n",
       "1    1197264398886350850  unfarenyc  Wed Nov 20 21:24:11 +0000 2019   \n",
       "2    1197262875410288643  unfarenyc  Wed Nov 20 21:18:08 +0000 2019   \n",
       "3    1197254191384842241  unfarenyc  Wed Nov 20 20:43:37 +0000 2019   \n",
       "4    1197251190075080709  unfarenyc  Wed Nov 20 20:31:42 +0000 2019   \n",
       "..                   ...        ...                             ...   \n",
       "195  1195812272792330249  unfarenyc  Sat Nov 16 21:13:57 +0000 2019   \n",
       "196  1195808664285790210  unfarenyc  Sat Nov 16 20:59:37 +0000 2019   \n",
       "197  1195756090966892545  unfarenyc  Sat Nov 16 17:30:42 +0000 2019   \n",
       "198  1195755807465447426  unfarenyc  Sat Nov 16 17:29:35 +0000 2019   \n",
       "199  1195732058812735489  unfarenyc  Sat Nov 16 15:55:13 +0000 2019   \n",
       "\n",
       "                                                  text  retweet_count  \n",
       "0    RT @Hurowittty: @unfarenyc 4 cops ticketing at...              1  \n",
       "1    RT @ironmonopoly: Cops hiding in 42nd/PABT ACE...              2  \n",
       "2    4 cops in uniform by the L train entrance at U...              2  \n",
       "3    3 uniformed cops at 57st/7th ave Q/N/R/W stati...              0  \n",
       "4    2 cops standing at the top of the stairs of th...              0  \n",
       "..                                                 ...            ...  \n",
       "195  3 cops by the turnstiles at the main entrance ...              0  \n",
       "196  Three cops at Grand Central turnstiles near 7 ...              3  \n",
       "197  3 cops at 47-50st Rockefeller center 50th st e...              1  \n",
       "198  RT @cabbage_rat: Blurry pic, but two cops on t...              3  \n",
       "199  Uniformed cops seen giving tickets last seen o...              5  \n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to twitter's api with given credentials\n",
    "api = twitter.Api(consumer_key='0ift2jAgEYQrWs8OP1f9TjRQ1',\n",
    "                      consumer_secret='qq9jNTaS3cG9wVc2Hxij3M0GuhAy72wNzFnBc9y1ejp2xh5dg4',\n",
    "                      access_token_key='144353594-pUtB5UxLeZHwZxJH4vPtFQMXAvgyQKTyvDanafog',\n",
    "                      access_token_secret='TvGH6dRf2J0PTKgBiSwWJ022j25PNBBaYUZQYWML1bDok')\n",
    "\n",
    "# to test if api is connected:\n",
    "# print(api.VerifyCredentials())\n",
    "\n",
    "statuses_list = api.GetUserTimeline(count=200,screen_name='unfarenyc') # Load @unfarenyc's timeline\n",
    "tweets = []\n",
    "for s in statuses_list:\n",
    "    tweets.append([s.id,s.user.screen_name,s.created_at,s.text,s.retweet_count])\n",
    "column_names = ['ID','user','created_at','text','retweet_count']\n",
    "tweetsdf = pd.DataFrame(tweets,columns = column_names)\n",
    "tweetsdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>user</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1197272944235483137</td>\n",
       "      <td>unfarenyc</td>\n",
       "      <td>Wed Nov 20 21:58:08 +0000 2019</td>\n",
       "      <td>RT @Hurowittty: @unfarenyc 4 cops ticketing at...</td>\n",
       "      <td>1</td>\n",
       "      <td>[RT, @, Hurowittty, :, @, unfarenyc, 4, cops, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1197264398886350850</td>\n",
       "      <td>unfarenyc</td>\n",
       "      <td>Wed Nov 20 21:24:11 +0000 2019</td>\n",
       "      <td>RT @ironmonopoly: Cops hiding in 42nd/PABT ACE...</td>\n",
       "      <td>2</td>\n",
       "      <td>[RT, @, ironmonopoly, :, Cops, hiding, in, 42n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1197262875410288643</td>\n",
       "      <td>unfarenyc</td>\n",
       "      <td>Wed Nov 20 21:18:08 +0000 2019</td>\n",
       "      <td>4 cops in uniform by the L train entrance at U...</td>\n",
       "      <td>2</td>\n",
       "      <td>[4, cops, in, uniform, by, the, L, train, entr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1197254191384842241</td>\n",
       "      <td>unfarenyc</td>\n",
       "      <td>Wed Nov 20 20:43:37 +0000 2019</td>\n",
       "      <td>3 uniformed cops at 57st/7th ave Q/N/R/W stati...</td>\n",
       "      <td>0</td>\n",
       "      <td>[3, uniformed, cops, at, 57st/7th, ave, Q/N/R/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1197251190075080709</td>\n",
       "      <td>unfarenyc</td>\n",
       "      <td>Wed Nov 20 20:31:42 +0000 2019</td>\n",
       "      <td>2 cops standing at the top of the stairs of th...</td>\n",
       "      <td>0</td>\n",
       "      <td>[2, cops, standing, at, the, top, of, the, sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>1195812272792330249</td>\n",
       "      <td>unfarenyc</td>\n",
       "      <td>Sat Nov 16 21:13:57 +0000 2019</td>\n",
       "      <td>3 cops by the turnstiles at the main entrance ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[3, cops, by, the, turnstiles, at, the, main, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>1195808664285790210</td>\n",
       "      <td>unfarenyc</td>\n",
       "      <td>Sat Nov 16 20:59:37 +0000 2019</td>\n",
       "      <td>Three cops at Grand Central turnstiles near 7 ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[Three, cops, at, Grand, Central, turnstiles, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>1195756090966892545</td>\n",
       "      <td>unfarenyc</td>\n",
       "      <td>Sat Nov 16 17:30:42 +0000 2019</td>\n",
       "      <td>3 cops at 47-50st Rockefeller center 50th st e...</td>\n",
       "      <td>1</td>\n",
       "      <td>[3, cops, at, 47-50st, Rockefeller, center, 50...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>1195755807465447426</td>\n",
       "      <td>unfarenyc</td>\n",
       "      <td>Sat Nov 16 17:29:35 +0000 2019</td>\n",
       "      <td>RT @cabbage_rat: Blurry pic, but two cops on t...</td>\n",
       "      <td>3</td>\n",
       "      <td>[RT, @, cabbage_rat, :, Blurry, pic, ,, but, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>1195732058812735489</td>\n",
       "      <td>unfarenyc</td>\n",
       "      <td>Sat Nov 16 15:55:13 +0000 2019</td>\n",
       "      <td>Uniformed cops seen giving tickets last seen o...</td>\n",
       "      <td>5</td>\n",
       "      <td>[Uniformed, cops, seen, giving, tickets, last,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ID       user                      created_at  \\\n",
       "0    1197272944235483137  unfarenyc  Wed Nov 20 21:58:08 +0000 2019   \n",
       "1    1197264398886350850  unfarenyc  Wed Nov 20 21:24:11 +0000 2019   \n",
       "2    1197262875410288643  unfarenyc  Wed Nov 20 21:18:08 +0000 2019   \n",
       "3    1197254191384842241  unfarenyc  Wed Nov 20 20:43:37 +0000 2019   \n",
       "4    1197251190075080709  unfarenyc  Wed Nov 20 20:31:42 +0000 2019   \n",
       "..                   ...        ...                             ...   \n",
       "195  1195812272792330249  unfarenyc  Sat Nov 16 21:13:57 +0000 2019   \n",
       "196  1195808664285790210  unfarenyc  Sat Nov 16 20:59:37 +0000 2019   \n",
       "197  1195756090966892545  unfarenyc  Sat Nov 16 17:30:42 +0000 2019   \n",
       "198  1195755807465447426  unfarenyc  Sat Nov 16 17:29:35 +0000 2019   \n",
       "199  1195732058812735489  unfarenyc  Sat Nov 16 15:55:13 +0000 2019   \n",
       "\n",
       "                                                  text  retweet_count  \\\n",
       "0    RT @Hurowittty: @unfarenyc 4 cops ticketing at...              1   \n",
       "1    RT @ironmonopoly: Cops hiding in 42nd/PABT ACE...              2   \n",
       "2    4 cops in uniform by the L train entrance at U...              2   \n",
       "3    3 uniformed cops at 57st/7th ave Q/N/R/W stati...              0   \n",
       "4    2 cops standing at the top of the stairs of th...              0   \n",
       "..                                                 ...            ...   \n",
       "195  3 cops by the turnstiles at the main entrance ...              0   \n",
       "196  Three cops at Grand Central turnstiles near 7 ...              3   \n",
       "197  3 cops at 47-50st Rockefeller center 50th st e...              1   \n",
       "198  RT @cabbage_rat: Blurry pic, but two cops on t...              3   \n",
       "199  Uniformed cops seen giving tickets last seen o...              5   \n",
       "\n",
       "                                        text_tokenized  \n",
       "0    [RT, @, Hurowittty, :, @, unfarenyc, 4, cops, ...  \n",
       "1    [RT, @, ironmonopoly, :, Cops, hiding, in, 42n...  \n",
       "2    [4, cops, in, uniform, by, the, L, train, entr...  \n",
       "3    [3, uniformed, cops, at, 57st/7th, ave, Q/N/R/...  \n",
       "4    [2, cops, standing, at, the, top, of, the, sta...  \n",
       "..                                                 ...  \n",
       "195  [3, cops, by, the, turnstiles, at, the, main, ...  \n",
       "196  [Three, cops, at, Grand, Central, turnstiles, ...  \n",
       "197  [3, cops, at, 47-50st, Rockefeller, center, 50...  \n",
       "198  [RT, @, cabbage_rat, :, Blurry, pic, ,, but, t...  \n",
       "199  [Uniformed, cops, seen, giving, tickets, last,...  \n",
       "\n",
       "[200 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tweetsdf['text'].apply(nltk.tokenize.word_tokenize) #\n",
    "tweets_nltk = nltk.text.Text(tokens) # A list of each tweet's single words\n",
    "tweetsdf['text_tokenized'] = tweets_nltk\n",
    "tweetsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Open the CSV file of subway station names\n",
    "stations = pd.read_csv(\"Stations.csv\")\n",
    "\n",
    "# Remove some common regular expressions from our station names\n",
    "stations['Stop Name'] = stations['Stop Name'].str.replace(\" - \",\" \")\n",
    "stations['Stop Name'] = stations['Stop Name'].str.replace(\"/\",\" \")\n",
    "stations['Stop Name'] = stations['Stop Name'].str.replace(\"''\",\"\")\n",
    "stations['Stop Name'] = stations['Stop Name'].str.replace(\"heights\",\"hts\")\n",
    "stations['Stop Name'] = stations['Stop Name'].str.replace(\"park\",\"pk\")\n",
    "stations['Stop Name'] = stations['Stop Name'].str.lower()\n",
    "\n",
    "# Fix some specific subway stop names\n",
    "\n",
    "\n",
    "# Initialize a dictionary of police sightings, initialize our sightings to be all 0\n",
    "stationSightings = dict.fromkeys(stations['Stop Name'],0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "processed_tweets = tweetsdf['text'].str.replace(\" - \",\" \")\n",
    "processed_tweets = processed_tweets.str.replace(\"-\",\" \")\n",
    "processed_tweets = processed_tweets.str.lower()\n",
    "processed_tweets = processed_tweets.str.replace(\"ave\",\"av\")\n",
    "processed_tweets = processed_tweets.str.replace(\"street\",\"st\")\n",
    "processed_tweets = processed_tweets.str.replace(\"heights\",\"hts\")\n",
    "tokened_tweets = processed_tweets.apply(nltk.tokenize.word_tokenize)\n",
    "\n",
    "# to play around with checking if any part of text is in dict.keys()\n",
    "count = 0\n",
    "for row in processed_tweets:\n",
    "    #print(row)\n",
    "    for word in nltk.tokenize.word_tokenize(row): #.apply(nltk.tokenize.word_tokenize):\n",
    "        if word[0].isdigit() & word.endswith('th'):\n",
    "            word = word[:-2]\n",
    "        elif word[0].isdigit() & word.endswith('nd'):\n",
    "            word = word[:-2]\n",
    "        elif word == 'park':\n",
    "            word = 'pk'\n",
    "        elif word == 'parkway':\n",
    "            word = 'pkwy'\n",
    "    for key in stationSightings.keys():\n",
    "        numfound = 0\n",
    "        tokenized_row = nltk.tokenize.word_tokenize(row)\n",
    "        if key in tokenized_row:\n",
    "            print(key,tokenized_row)\n",
    "            numfound += 1\n",
    "        #numfound = tokenized_row.find(key)\n",
    "        if numfound > 0:\n",
    "            stationSightings[key] += 1\n",
    "            found = 1\n",
    "            count += 1\n",
    "            break\n",
    "    if found == 0:\n",
    "        print(row)\n",
    "    \n",
    "#print(stationSightings)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_words(unigram):\n",
    "    if unigram[0].isdigit() & unigram.endswith('st'):\n",
    "        unigram = unigram[:-2]\n",
    "    elif unigram[0].isdigit() & unigram.endswith('nd'):\n",
    "        unigram = unigram[:-2]\n",
    "    elif unigram[0].isdigit() and unigram.endswith('th'):\n",
    "        unigram = unigram[:-2]\n",
    "    elif unigram == 'park':\n",
    "        unigram = 'pk'\n",
    "    elif unigram == 'parkway':\n",
    "        unigram = 'pkwy'\n",
    "    elif unigram == 'heights':\n",
    "        unigram = 'hts'\n",
    "    return unigram\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rt', '@', 'hurowittty', ':', '@', 'unfarenyc', '4', 'cops', 'ticketing', 'at', 'fulton', 'inside', 'the', 'turnstiles', 'by', 'the', 'chicken', 'stand', 'https', ':', '//tco/zue27w0mge']\n",
      "['rt', '@', 'ironmonopoly', ':', 'cops', 'hiding', 'in', '42nd/pabt', 'acenqrw123', 'station', ',', 'saw', 'two', ',', 'may', 'be', 'more', 'https', ':', '//tco/zpult7q3zt']\n",
      "['4', 'cops', 'in', 'uniform', 'by', 'the', 'l', 'train', 'entrance', 'at', 'union', 'square', '(', '4:15pm', ')']\n",
      "['3', 'uniformed', 'cops', 'at', '57st/7th', 'av', 'q/n/r/w', 'station', 'north', 'entrance', 'past', 'turnstiles', '(', '3:42pm', ')']\n",
      "['2', 'cops', 'standing', 'at', 'the', 'top', 'of', 'the', 'stairs', 'of', 'the', 'downtown', '456', 'platform', 'at', 'union', 'sq', '(', '3:31pm', ')']\n",
      "['3', 'cops', 'writing', 'tickets', 'at', 'clinton', 'washington', 'g', 'station', '(', '2:27pm', ')']\n",
      "['at', 'least', '3', 'uniformed', 'cops', 'on', 'the', 'uptown', 'a/c', 'platform', 'at', 'the', 'utica', 'a/c', 'station', '(', '1:36pm', ')']\n",
      "['rt', '@', 'alexremnick', ':', '‚Äú', 'homeless', 'outreach', '‚Äù', 'cop', 'outside', '5th', 'avnue', '7fm', 'stop', '@', 'unfarenyc', 'https', ':', '//tco/ttmdy3kac8']\n",
      "['3', 'cops', 'on', 'the', 'northbound', '2/3', 'platform', 'at', 'atlantic', 'barclays', '(', '12:24pm', ')']\n",
      "['rt', '@', 'decolonize_this', ':', 'happening', 'now', '‚ö†Ô∏è', 'y', '‚Äô', 'all', 'this', 'shit', 'ain', '‚Äô', 't', 'normal', '‚Äî', 'and', 'we', 'won', '‚Äô', 't', 'accept', 'this', '‚ÄºÔ∏è', 'turn', 'up', 'on', 'fri', ',', 'nov', '22', '‚Äî', 'link', 'in', 'bio', 'we', 'a‚Ä¶']\n",
      "['2', 'uniformed', 'cops', 'in', 'the', 'utica', '3/4', 'station', 'by', 'the', 'turnstiles', 'at', 'the', 'utica', 'and', 'eastern', 'pkwy', 'entrance', '(', '11:51am', ')']\n",
      "['rt', '@', 'chrisecrowley', ':', 'trio', 'of', 'cops', 'lurking', 'out', 'of', 'sight', 'by', 'the', 'turnstiles', 'at', 'myrtle', 'broadway', ',', 'looking', 'like', 'they', '‚Äô', 're', 'waiting', 'for', 'turnstile', 'jumpe‚Ä¶']\n",
      "['4', 'cops', 'at', 'a', 'bag', 'check', 'table', 'uptown', 'rw', 'at', '23rd', 'st', '(', '10:27am', ')']\n",
      "['two', 'cops', 'inside', 'the', 'turnstile', 'at', 'prospect', 'park', 'b/q/s', ',', 'lincoln', 'rd', 'entrance', '(', '10:20am', ')']\n",
      "['3', 'cops', 'behind', 'the', 'turnstiles', 'at', '233rd', 'st', 'on', 'the', '2/5', 'line', '(', '10:04am', ')']\n",
      "['2', 'cops', 'watching', 'turnstiles', 'at', 'parkchester', '6', 'train', 'station', '(', '10:07am', ')']\n",
      "['rt', '@', 'sierritaxo', ':', '11', 'cops', 'standing', 'by', 'the', 'turnstiles', 'at', '3rd', 'av/149st', 'while', 'half', 'of', 'the', 'machines', 'don', '‚Äô', 't', 'even', 'work', '@', 'unfarenyc']\n",
      "['cop', 'hiding', 'by', 'the', 'ticket', 'booth', 'at', '167', 'd', 'station', 'on', 'the', 'grand', 'concourse', 'side', '(', '9:52am', ')']\n",
      "['rt', '@', 'enjen99', ':', '@', 'unfarenyc', 'jay', 'st/metrotech', '6', 'cops', 'on', 'uptown', 'a/c', 'and', 'f', 'platform', 'standing', 'around', 'looking', 'at', 'their', 'phones', 'and', 'talking', 'about', 'babi‚Ä¶']\n",
      "['2', 'cops', 'got', 'off', 'the', 'uptown', '2', 'train', 'at', 'clark', '(', '9:24am', ')']\n",
      "['cops', 'behind', 'turnstiles', '@', '32nd', '&', 'amp', ';', 'broadway', 'entrance', 'to', 'nqrw', '&', 'amp', ';', 'bdfm', 'at', 'herald', 'square', 'station', '(', '9:25am', ')']\n",
      "['cops', 'inside', 'times', 'square', '42nd', 'st', 'port', 'authority', 'entrance', '(', 'near', 'downtown', 'ace', ')', '(', '9:10am', ')']\n",
      "['3', 'cops', 'watching', '40th/6th', 'turnstile', 'inside', '42nd', 'bryant', 'park', 'b/d/f/m', '(', '9:07am', ')']\n",
      "['3', 'cops', 'at', 'union', 'turnpike/kew', 'gardens', 'e/f', 'at', 'the', '78th', 'av', 'and', 'queens', 'blvd', 'entrance', '(', '8:58am', ')']\n",
      "['still', 'there', 'as', 'of', '8:55am', 'https', ':', '//tco/qxfn2e17ix']\n",
      "['cops', 'on', 'uptown', 'nqr', 'platform', 'in', 'union', 'square', 'station', '(', '9:00am', ')']\n",
      "['2', 'cops', 'in', 'uniform', 'on', 'the', 'uptown', 'a/c/b/d', 'platform', 'at', '59th', 'st/columbus', 'cir', '(', '8:56am', ')']\n",
      "['bag', 'check', 'at', 'dekalb', 'b/q/r', '(', '8:48am', ')']\n",
      "['three', 'cops', 'writing', 'tickets', 'inside', 'the', 'turnstiles', 'at', 'southern', 'entrance', 'of', 'franklin', 'av/botanic', 'garden', '2/3/4/5', '(', '8:17am', ')']\n",
      "['2', 'uniformed', 'police', 'waiting', '(', 'hidden', ')', 'at', 'the', 'fulton', 'washington', 'entrance', 'of', 'the', 'clinton', 'washington', 'c', '(', '8:17am', ')']\n",
      "['cops', 'at', 'select', 'bus', 'stop', '23rd', 'and', '6th', '(', '8:01am', ')']\n",
      "['two', 'cops', 'before', 'the', 'turnstiles', 'at', 'dekalb', 'l', 'nw', 'corner', '(', '6:10am', ')']\n",
      "['rt', '@', 'swipeitforward', ':', 'community', 'aler', 'happening', 'now', ':', 'nypd', 'looking', 'for', 'homeless', 'on', 'the', 'platform', 'https', ':', '//tco/8p0bkm5a73']\n",
      "['union', 'sq', '4', 'cops', 'at', 'the', '16th', 'st/', 'union', 'sq', 'west', 'entrance', '(', '9:18', 'pm', ')']\n",
      "['rt', '@', 'caitlinwolper', ':', '4', 'cops', 'doing', 'absolutely', 'nothing', 'but', 'chatting', 'at', 'union', 'square', 'in', 'front', 'of', 'turnstiles', '@', 'unfarenyc']\n",
      "['rt', '@', 'letmehoswayyou', ':', '@', 'unfarenyc', \"b'way\", 'lafayette', '8:47pm', 'https', ':', '//tco/x5gveti0rj']\n",
      "['cops', 'downtown', 'ace', 'and', 'candy', 'store', 'at', '14th', 'st/8th', 'av', '(', '8:42pm', ')']\n",
      "['cops', 'at', 'court', 'square', 'emg7', 'station', 'on', 'both', 'sides', 'of', 'the', 'turnstile', ',', 'three', 'uniformed', 'on', 'the', 'pre', 'swipe', 'side', 'and', 'one', 'uni‚Ä¶', 'https', ':', '//tco/hzps9pbtpb']\n",
      "['71st', 'continental', 'forest', 'hills', 'efmr', 'station', 'cops', 'in', 'uniform', 'and', 'plainclothes', 'making', 'an', 'arrest', '(', '7:20pm', ')']\n",
      "['uniformed', 'cops', 'at', 'mrytle', 'wyckoff', 'l', 'platform', '(', '7:20pm', ')']\n",
      "['3', 'still', 'there', '(', '6:54pm', ')', 'https', ':', '//tco/ocmqycb7bo']\n",
      "['hey', ',', 'three', 'cops', 'standing', 'by', 'the', 'turnstiles', 'at', '125', 'and', 'lex', '(', '6:52pm', ')']\n",
      "['at', 'least', 'three', 'cops', 'inside', 'turnstiles', 'at', 'grand', 'central', 'near', 'entrance', 'from', 'inside', 'the', 'train', 'station', '(', '6:51pm', ')']\n",
      "['3', 'uniformed', 'cops', 'at', 'the', 'bottom', 'of', 'the', 'escalator', 'at', 'the', 'jay', 'st', 'and', 'willoughby', 'entrance', 'to', 'jay', 'st', 'metro', 'tech‚Ä¶', 'https', ':', '//tco/kanfxi7ybo']\n",
      "['5', 'uniformed', 'cops', 'on', 'the', 'brooklyn', 'bound', 'platform', 'of', 'the', 'ac/f', 'at', 'jay', 'st', '(', '6:08pm', ')']\n",
      "['2', 'cops', 'in', '47', '50th', 'rockefeller', 'center', 'bdfm', '(', '5:58pm', ')']\n",
      "['4', 'uniformed', 'cops', 'behind', 'turnstiles', 'at', 'bway/lafayette', 'at', 'bway/houston', 'entrance', '(', '5:46', ')']\n",
      "['2', 'cops', 'in', 'uniform', 'by', 'the', 'construction', ',', 'dekalb', 'l', 'stanhope', 'entrance', '(', '5:42pm', ')']\n",
      "['14st', '1/2/3/f/l', ',', '4', 'cops', 'in', 'uniform', 'by', 'the', 'booth', 'watching', 'turnstiles', '(', '5:41pm', ')']\n",
      "['6', 'uniformed', 'cops', 'at', '57st/7th', 'av', 'q/n/r/w', 'station', 'north', 'entrance', 'past', 'turnstiles', '(', '5:11pm', ')']\n",
      "['still', 'there', '(', '5:11pm', ')', 'https', ':', '//tco/f2byf6wv0m']\n",
      "['2', 'uniformed', 'cops', 'outside', 'the', 'downtown', 'bound', '2/5', 'turnstiles', '149th', 'st', 'and', '3rd', 'av', '(', '5:02pm', ')']\n",
      "['one', 'cop', 'at', 'union', 'square', 'w', '16th', ',', 'in', 'a', 'vest', ',', 'watching', 'turnstile', '(', '4:54pm', ')']\n",
      "['they', 'got', 'off', 'at', 'hoyt', 'schermerhorn', '(', '4:31pm', ')', 'https', ':', '//tco/lpn0tjn8zn']\n",
      "['rt', '@', 'uh_akua', ':', 'police', 'at', 'bleecker', 'st/broadway', 'lafayette', 'station', '@', 'unfarenyc']\n",
      "['cops', 'at', 'court', 'square', 'in', 'queens', 'near', '44th', 'st', 'turnstiles', '(', '4:20pm', ')']\n",
      "['2', 'uniformed', 'cops', 'in', 'the', 'passageway', 'from', 'the', 'e/m', 'to', 'the', 'g', 'at', 'court', 'square', ',', 'across', 'from', 'the', 'turnstiles', '(', '4:11pm', ')']\n",
      "['rt', '@', 'weednglitter', ':', 'the', 'boys', '@', 'unfarenyc', '@', '116', '2/3', 'station', 'https', ':', '//tco/v4cq1cewgo']\n",
      "['rt', '@', 'weednglitter', ':', 'police', 'at', '116', '2/3', 'station', 'downtown', 'side']\n",
      "['rt', '@', 'monsieursupreme', ':', '@', 'unfarenyc', 'also', 'on', '116', 'on', 'the', '6', 'line', 'downtown', 'side', 'by', 'machines', 'https', ':', '//tco/zgpg4bqjgo']\n",
      "['4', 'cops', 'by', 'turnstiles', 'at', 'kings', 'highway', 'b/q', ',', '16th', 'st', 'and', 'quentin', 'road', 'entrance', '(', '2:07pm', ')']\n",
      "['lexington', 'line', 'https', ':', '//tco/6gmyosltqm']\n",
      "['rt', '@', 'vl0ko', ':', '@', 'unfarenyc', 'uniformed', 'cops', 'at', 'myrtle', 'broadway', 'standing', 'by', 'the', 'exit', 'door']\n",
      "['4', 'cops', 'at', '42nd', 'st', 'times', 'square', 'in', 'the', 'hallway', 'between', 'the', '123', 'and', 'the', 'nqrw', '(', '12:34pm', ')']\n",
      "['2', 'cops', 'with', 'bag', 'check', 'table', 'at', 'myrtle', 'wykoff', 'l', '(', 'entrance', 'by', 'the', 'planet', 'fitness', ')', '(', '11:34am', ')']\n",
      "['3', 'cops', 'in', 'uniform', 'writing', 'tickets', 'at', '207', 'a', 'platform', '(', '11:07am', ')']\n",
      "['rt', '@', 'dirtypeaches', ':', '@', 'unfarenyc', 'three', 'on', 'jackson', 'avnue', 'on', 'the', '2/5', 'line', 'in', 'the', 'bronx', 'https', ':', '//tco/zlt78zycuz']\n",
      "['rt', '@', 'dclnzhang', ':', '@', 'unfarenyc', '3', 'cops', 'in', 'uniform', 'checking', 'bags', 'in', 'the', 'underground', 'entrance', 'at', 'myrtle', 'wyckoff']\n",
      "['2', 'uniformed', 'cops', 'on', 'the', 'halsey', 'l', 'canarsie', 'bound', 'platform', '(', '9:49pm', ')']\n",
      "['two', 'cops', 'posted', 'up', 'with', 'ticket', 'books', 'in', 'hand', '@', '167', 'd', 'train', 'd/t', 'platform', '(', '9:48am', ')']\n",
      "['two', 'cops', 'in', 'uniform', 'just', 'got', 'off', 'with', 'ticket', 'books', 'in', 'hand', '@', '167', 'd', 'train', 'downtown', 'platform', 'and', 'posted', 'up', '(', '9:45am', ')']\n",
      "['2', 'uniformed', 'cops', 'at', 'the', 'atlantic', 'barclays', 'b/q', 'hanson', 'st', 'entrance', ';', 'after', 'the', 'escalator', ',', 'above', 'the', 'stairs', '(', '9:39am', ')']\n",
      "['cop', 'standing', 'the', 'stairwell', 'of', 'the', '125st', 'a/b/c/d', 'stop', ';', 'downtown', 'stairwell', 'in', 'the', '127th', '&', 'amp', ';', 'st', 'nicholas', 'entrance', '(', '9:38‚Ä¶', 'https', ':', '//tco/pf6uipvrap']\n",
      "['rt', '@', 'basura_babe', ':', '@', 'unfarenyc', '2', 'uniformed', 'cops', 'walking', 'around', 'the', 'uptown', '6', 'platform', '@', '59', '&', 'amp', ';', 'lex']\n",
      "['bag', 'check', 'near', 'turnstiles', 'at', 'metropolitan', 'g', '(', '8:54am', ')']\n",
      "['2', 'cops', 'at', '59', 'columbus', 'circle', 'by', 'the', '58th', 'st', 'ac/bd', 'entrance', '(', '8:45am', ')']\n",
      "['cop', 'spotted', 'waiting', 'ahead', 'of', 'the', 'turnstiles', 'at', 'cortelyou', 'q', '(', '8:45am', ')']\n",
      "['multiple', 'heavily', 'armed', 'cops', 'at', 'top', 'of', 'subway', 'exit', 'stairs', ',', 'grand', 'central', 'terminal', '(', '8:30am', ')']\n",
      "['2', 'uniformed', 'cops', 'by', '43rd', 'and', '8th', 'entrance', 'to', '42nd', 'st', '(', '8:31pm', ')']\n",
      "['at', 'least', '5', 'officers', 'at', 'the', 'downtown', '4/5/6', 'at', '86th', '&', 'amp', ';', 'lex', '(', '7:54pm', ')']\n",
      "['2', 'police', 'at', 'franklin', 'avnue', '2/3/4/5', '(', '7:00am', ')']\n",
      "['4', 'cops', 'at', 'bedford', 'l', 'stop', ',', 'watching', 'turnstyles', 'at', 'the', 'driggs/north', '7th', 'exit', '(', '8:50pm', ')']\n",
      "['rt', '@', 'mta_hostage', ':', '@', 'unfarenyc', 'üê∑üëÆüèªüëÆüèªüê∑', 'at', 'the', 'turnstiles', 'at', '57th', 'st‚Äî7th', 'av', '(', 'n/r/w', 'line', ')']\n",
      "['3', '4', 'cops', 'hanging', 'out', 'behind', 'the', 'emergency', 'exit', 'at', 'the', 'prospect', 'park', 'b/q/s', 'station', '(', '7:13pm', ')']\n",
      "['@', 'michelle_mc_g', 'what', 'station', '?']\n",
      "['two', 'uniformed', 'cops', 'outside', 'of', 'the', 'turnstiles', 'at', 'the', 'west', '4th', 'st', 'wavrly', 'place', 'entrance', '(', '6:45pm', ')']\n",
      "['rt', '@', 'notyrlawyer', ':', 'jay', 'st', 'metro', 'tech', '@', 'unfarenyc', 'willoughby', 'entrance', 'and', 'on', 'the', 'platform', 'for', 'the', 'queens', 'bound', 'ac', 'https', ':', '//tco/jwuz9j4zr8']\n",
      "['report', 'of', 'cops', 'harassing', 'people', 'at', 'union', 'sq', 'station', '(', '2:23pm', ')']\n",
      "['rt', '@', 'ipsadixi', ':', '2', 'uniforms', 'on', 'the', 'uptown', '1', 'leaving', '103rd', 'right', 'now', '@', 'unfarenyc']\n",
      "['1', 'cop', 'at', 'hoyt', 'schermerhorn', 'hidden', 'at', 'top', 'of', 'queens', 'bound', 'stairs', '(', '2:42pm', ')']\n",
      "['4', 'cops', 'at', 'the', '116th', 'b/c', 'uptown', 'platform', '(', '2:22pm', ')']\n",
      "['2', 'cops', 'on', 'downtown', '6', 'leaving', '110th', '(', '2:00pm', ')']\n",
      "['bag', 'check', 'at', 'jamaica', 'center', 'station', '(', '1:15pm', ')']\n",
      "['two', 'pigs', 'inside', 'the', 'turnstile', 'at', 'the', 'jay', 'st', 'metro', 'tech', 'entrance', 'opposite', 'one', 'metrotech', 'center', '(', '10:12am', ')']\n",
      "['rt', '@', 'lesbianpameia', ':', '@', 'unfarenyc', '2', 'harassing', 'a', 'homeless', 'person', 'at', 'south', 'entrance', 'of', 'ce', 'at', '23rd', 'st', ',', 'not', 'sure', 'how', 'long', 'they', '‚Äô', 'll', 'stick', 'around‚Ä¶']\n",
      "['2', 'uniformed', 'cops', 'outside', 'turnstiles', 'at', 'columbus', 'circle', ',', '58th', 'st', 'entrance', '(', '8:41am', ')']\n",
      "['rt', '@', 'diasporaafro_', ':', '@', 'unfarenyc', 'dumb', 'police', 'at', '3av', '149', 'issuing', 'tickets']\n",
      "['2', 'uniformed', 'cops', 'at', 'broadway', 'lafayette', ',', 'bottom', 'of', 'stairs', 'at', 'the', 'broadway/houston', 'se', 'entrance', '(', '7:45pm', ')']\n",
      "['2', 'uniformed', 'at', '103rd', 'st', '6', 'train', '(', '10:39', 'pm', ')']\n",
      "['two', 'uniformed', 'cops', 'watching', 'turnstiles', 'at', 'queens', 'bound', 'nostrand', 'a/c', 'stop', '(', '9:38pm', ')']\n",
      "['rt', '@', 'kaylakireeva', ':', '@', 'unfarenyc', '3', 'cops', 'in', 'front', 'of', 'the', 'turnstile', 'at', 'm', 'and', 'j', 'myrtle', 'broadway', '9:22', 'pm']\n",
      "['rt', '@', 'stsblognyc', ':', 'hello', '\\u2066', '@', 'unfarenyc\\u2069', ':', '6', 'cops', 'at', 'jay', 'st', 'in', 'brooklyn', 'sunday', 'night', 'no', 'reason', 'https', ':', '//tco/qhsrslvo75']\n",
      "['two', 'cops', 'at', 'prospect', 'park', 'q/s', ';', 'flatbush/ocean', 'entrance', ',', 'one', 'by', 'exit', 'gate', ',', 'one', 'by', 'fare', 'machines', '(', '5:08', 'pm', ')']\n",
      "['four', 'cops', 'union', 'square', 'l', ',', 'center', 'of', 'platform', '(', '3:24pm', ')']\n",
      "['rt', '@', 'gargarak', ':', '@', 'unfarenyc', 'two', 'cops', 'in', 'uniform', 'at', 'west', '4th/washington', 'square', ',', 'north', 'end', ',', 'in', 'the', 'mezzanine', 'between', 'the', 'a/c/e', 'and', 'bdfm', 'platforms']\n",
      "['myrtle', 'wycoff', '2', 'cops', 'on', 'mezzanine', 'at', 'bottom', 'of', 'big', 'staircase', 'with', 'ticket', 'books', 'out', '(', '2:54', 'pm', ')']\n",
      "['rt', '@', 'furiousmaenad', ':', '@', 'unfarenyc', 'approx', 'eight', 'transit', 'cops', 'checking', 'for', 'bus', 'tickets', 'on', 'the', 'westbound', 'm14', 'lines', 'at', 'third', 'av']\n",
      "['rt', '@', 'mrejfox', ':', '@', 'unfarenyc', 'two', 'uniforms', 'at', 'myrtle', 'broadway', 'jmz']\n",
      "['rt', '@', 'tinalglover', ':', '@', 'unfarenyc', 'uniforms', 'at', '137', 'str', '1', 'train', 'downtown', 'side']\n",
      "['one', 'cop', 'at', 'union', 'square', 'l', ',', 'boarding', 'brooklyn', 'bound', 'l', 'train', '@', '9:20pm']\n",
      "['two', 'cops', 'on', 'the', 'nyc', 'bound', 'f', 'train', 'departing', 'from', '179th', 'jamaica', '(', '6:52pm', ')']\n",
      "['three', 'cops', 'hiding', 'by', 'the', 'franklin', 'c', 'train', 'the', 'st', 'entrance', 'that', 'doesn', '‚Äô', 't', 'hav', 'the', 'booth', '(', '6:37pm', ')']\n",
      "['two', 'uniformed', 'cops', 'at', '15th', 'and', 'union', 'square', 'east', '‚Äî', 'they', '‚Äô', 're', 'hiding', 'around', 'the', 'corner', ',', 'plus', 'by', 'the', 'n/q/r/w', '(', '5:46pm', ')']\n",
      "['rt', '@', 'kendrybird', ':', '@', 'unfarenyc', 'cops', 'at', 'bdway', 'lafayette', ',', 'outside', 'turnstiles', 'at', 'broadway', '/houston']\n",
      "['rt', '@', 'mtferal', ':', '@', 'unfarenyc', '2', 'cops', 'at', 'myrtle', 'broadway', 'jmz']\n",
      "['2', 'cops', 'at', 'myrtle', 'broadway', 'before', 'turnstiles', '(', '4:40pm', ')']\n",
      "['two', 'uniformed', 'cops', 'on', 'the', 'astoria', 'ditmars', 'bound', 'n', 'got', 'on', 'at', 'broadway', '(', '4:28pm', ')']\n",
      "['rt', '@', 'riningear', ':', 'two', 'cops', 'right', 'at', 'whole', 'foods', 'union', 'square', 'entrance', ':', 'v', 'https', ':', '//tco/jbqmpqjsew']\n",
      "['3', 'cops', 'by', 'the', 'turnstiles', 'at', 'the', 'main', 'entrance', 'to', 'the', '1', 'stop', 'at', '103rd', 'st', '(', '4:13pm', ')']\n",
      "['three', 'cops', 'at', 'grand', 'central', 'turnstiles', 'near', '7', 'train', 'entrance', 'bag', 'check', 'flashing', 'summons', 'books', '(', '3:58pm', ')']\n",
      "['rt', '@', 'cabbage_rat', ':', 'blurry', 'pic', ',', 'but', 'two', 'cops', 'on', 'the', 'south', 'end', 'of', 'the', 'acf', 'jay', 'st', 'stop', '@', 'unfarenyc', 'https', ':', '//tco/1kx3a4xz3x']\n",
      "['uniformed', 'cops', 'seen', 'giving', 'tickets', 'last', 'seen', 'on', 'manhattan', 'bound', 'jay', 'st', 'a/c/f', 'platform', 'at', '(', '9:54am', ')']\n",
      "78\n"
     ]
    }
   ],
   "source": [
    "processed_tweets = tweetsdf['text'].str.replace(\" - \",\" \")\n",
    "processed_tweets = processed_tweets.str.replace(\"-\",\" \")\n",
    "processed_tweets = processed_tweets.str.replace(\".\",\"\")\n",
    "processed_tweets = processed_tweets.str.lower()\n",
    "processed_tweets = processed_tweets.str.replace(\"ave\",\"av\")\n",
    "processed_tweets = processed_tweets.str.replace(\"street\",\"st\")\n",
    "tokened_tweets = processed_tweets.apply(nltk.tokenize.word_tokenize)\n",
    "\n",
    "# Let's start with brute force! Like a full on for loop\n",
    "total_processed = 0 # Set our counter for how many tweets we have found the station for to none\n",
    "for row in tokened_tweets: # For each tweet\n",
    "    found = 0 # Reset 'found': we haven't figured out which station this tweet is referring to yet! \n",
    "            \n",
    "    for bigram in nltk.bigrams(row): # First check every combo of tokens in the tweet for if they're a subway name\n",
    "        if found == 1: # if we've already found the tweet's subway station\n",
    "            total_processed += 1\n",
    "            break # break out of this loop, process the next tweet\n",
    "        one, two = bigram # unpack the bigram in case it's backwards\n",
    "        one = process_words(one)\n",
    "        two = process_words(two)\n",
    "        if one+\" \"+two in stationSightings.keys(): # if this bigram is a subway name\n",
    "            stationSightings[one+\" \"+two] += 1 # incremement that we've seen this subway station\n",
    "            found = 1 # signal that we've found this tweet's subway station\n",
    "        elif two+\" \"+one in stationSightings.keys(): # if the bigrams backwards is a subway name\n",
    "            stationSightings[two+\" \"+one] += 1 # increment that we've seen this station\n",
    "            found = 1 # signal that we've found this tweet's subway station\n",
    "    if found != 1: # if no bigram was found, find a trigram\n",
    "         for trigram in nltk.trigrams(row): # for each trigram made of the tweet's tokens\n",
    "                if found == 1: # If we've since found the tweet's subway station\n",
    "                    total_processed += 1 # Add to our counter of number of tweets we have found the station for\n",
    "                    break # break outta here, onto the next tweet!\n",
    "                one, two, three = trigram # unpack the 3 stations \n",
    "                one = process_words(one)\n",
    "                two = process_words(two)\n",
    "                three = process_words(three)\n",
    "                if one+\" \"+two+\" \"+three in stationSightings.keys():\n",
    "                    stationSightings[one+\" \"+two+\" \"+three] += 1\n",
    "                    found = 1\n",
    "                elif one+\" \"+three+\" \"+two in stationSightings.keys():\n",
    "                    stationSightings[one+\" \"+three+\" \"+two] += 1\n",
    "                    found = 1\n",
    "                elif two+\" \"+three+\" \"+one in stationSightings.keys():\n",
    "                    stationSightings[two+\" \"+three+\" \"+one] += 1\n",
    "                    found = 1  \n",
    "                elif two+\" \"+one+\" \"+three in stationSightings.keys():\n",
    "                    stationSightings[two+\" \"+one+\" \"+three] += 1\n",
    "                    found = 1\n",
    "                elif three+\" \"+one+\" \"+two in stationSightings.keys():\n",
    "                    stationSightings[three+\" \"+one+\" \"+two] += 1\n",
    "                    found = 1\n",
    "                elif three+\" \"+two+\" \"+one in stationSightings.keys():\n",
    "                    stationSightings[three+\" \"+two+\" \"+one] += 1\n",
    "                    found = 1\n",
    "    if found != 1: # If we did not find the station name in any trigrams\n",
    "        for fourgram in nltk.ngrams(row,4): # For each fourgram in the tweet\n",
    "            if found == 1: # If we found the station at the last iteration\n",
    "                total_processed += 1 # Add to our counter of total processed tweets\n",
    "                break # Break out of this loop, time to decipher the next tweet!\n",
    "            one, two, three, four = fourgram # Split apart the fourgram for processing\n",
    "            one = process_words(one) # Process unigram one, two, three and four\n",
    "            two = process_words(two) # According to our function defined above.\n",
    "            three = process_words(three)\n",
    "            four = process_words(four)\n",
    "            if one+\" \"+two+\" \"+three+\" \"+four in stationSightings.keys():\n",
    "                stationSightings[one+\" \"+two+\" \"+three+\" \"+four] += 1\n",
    "                found = 1\n",
    "            elif one+\" \"+two+\" \"+four+\" \"+three in stationSightings.keys():\n",
    "                stationSightings[one+\" \"+two+\" \"+four+\" \"+three] += 1\n",
    "                found = 1\n",
    "            elif one+\" \"+three+\" \"+four+\" \"+two in stationSightings.keys():\n",
    "                stationSightings[one+\" \"+three+\" \"+four+\" \"+two] += 1\n",
    "                found = 1\n",
    "            elif one+\" \"+three+\" \"+two+\" \"+four in stationSightings.keys():\n",
    "                stationSightings[one+\" \"+three+\" \"+two+\" \"+four] += 1\n",
    "                found = 1\n",
    "            elif one+\" \"+four+\" \"+three+\" \"+two in stationSightings.keys():\n",
    "                stationSightings[one+\" \"+four+\" \"+three+\" \"+two] += 1\n",
    "                found = 1\n",
    "            elif one+\" \"+four+\" \"+two+\" \"+three in stationSightings.keys():\n",
    "                stationSightings[one+\" \"+four+\" \"+two+\" \"+three] += 1\n",
    "                found = 1\n",
    "                \n",
    "            elif two+\" \"+one+\" \"+three+\" \"+four in stationSightings.keys():\n",
    "                stationSightings[two+\" \"+one+\" \"+three+\" \"+four] += 1\n",
    "                found = 1\n",
    "            elif two+\" \"+one+\" \"+four+\" \"+three in stationSightings.keys():\n",
    "                stationSightings[two+\" \"+one+\" \"+four+\" \"+three] += 1\n",
    "                found = 1\n",
    "            elif two+\" \"+three+\" \"+one+\" \"+four in stationSightings.keys():\n",
    "                stationSightings[two+\" \"+three+\" \"+one+\" \"+four] += 1\n",
    "                found = 1\n",
    "            elif two+\" \"+three+\" \"+four+\" \"+one in stationSightings.keys():\n",
    "                stationSightings[two+\" \"+three+\" \"+four+\" \"+one] += 1\n",
    "                found = 1\n",
    "            elif two+\" \"+four+\" \"+one+\" \"+three in stationSightings.keys():\n",
    "                stationSightings[two+\" \"+four+\" \"+one+\" \"+three] += 1\n",
    "                found = 1\n",
    "            elif two+\" \"+four+\" \"+three+\" \"+one in stationSightings.keys():\n",
    "                stationSightings[two+\" \"+four+\" \"+three+\" \"+one] += 1\n",
    "                found = 1\n",
    "            \n",
    "            elif three+\" \"+one+\" \"+two+\" \"+four in stationSightings.keys():\n",
    "                stationSightings[three+\" \"+one+\" \"+two+\" \"+four] += 1\n",
    "                found = 1\n",
    "            elif three+\" \"+one+\" \"+four+\" \"+two in stationSightings.keys():\n",
    "                stationSightings[three+\" \"+one+\" \"+four+\" \"+two] += 1\n",
    "                found = 1\n",
    "            elif three+\" \"+two+\" \"+one+\" \"+four in stationSightings.keys():\n",
    "                stationSightings[three+\" \"+two+\" \"+one+\" \"+four] += 1\n",
    "                found = 1\n",
    "            elif three+\" \"+two+\" \"+four+\" \"+one in stationSightings.keys():\n",
    "                stationSightings[three+\" \"+two+\" \"+four+\" \"+one] += 1\n",
    "                found = 1\n",
    "            elif three+\" \"+four+\" \"+one+\" \"+two in stationSightings.keys():\n",
    "                stationSightings[three+\" \"+four+\" \"+one+\" \"+two] += 1\n",
    "                found = 1\n",
    "            elif three+\" \"+four+\" \"+two+\" \"+one in stationSightings.keys():\n",
    "                stationSightings[three+\" \"+four+\" \"+two+\" \"+one] += 1\n",
    "                found = 1\n",
    "            \n",
    "            elif four+\" \"+one+\" \"+two+\" \"+three in stationSightings.keys():\n",
    "                stationSightings[four+\" \"+one+\" \"+two+\" \"+three] += 1\n",
    "                found = 1\n",
    "            elif four+\" \"+one+\" \"+three+\" \"+two in stationSightings.keys():\n",
    "                stationSightings[four+\" \"+one+\" \"+three+\" \"+two] += 1\n",
    "                found = 1\n",
    "            elif four+\" \"+two+\" \"+one+\" \"+three in stationSightings.keys():\n",
    "                stationSightings[four+\" \"+two+\" \"+one+\" \"+three] += 1\n",
    "                found = 1\n",
    "            elif four+\" \"+two+\" \"+three+\" \"+one in stationSightings.keys():\n",
    "                stationSightings[four+\" \"+two+\" \"+three+\" \"+one] += 1\n",
    "                found = 1\n",
    "            elif four+\" \"+three+\" \"+one+\" \"+two in stationSightings.keys():\n",
    "                stationSightings[four+\" \"+three+\" \"+one+\" \"+two] += 1\n",
    "                found = 1\n",
    "            elif four+\" \"+three+\" \"+two+\" \"+one in stationSightings.keys():\n",
    "                stationSightings[four+\" \"+three+\" \"+two+\" \"+one] += 1\n",
    "                found = 1\n",
    "    if found != 1: # If we still haven't found the station\n",
    "        print(row) # For self to continue adding parsers\n",
    "        pass\n",
    "                \n",
    "print(total_processed)\n",
    "#pd.plot(stationSightings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "times sq 42 st              1.0\n",
       "canal st                    1.0\n",
       "city hall                   1.0\n",
       "jay st metrotech            1.0\n",
       "union st                    2.0\n",
       "25 st                       1.0\n",
       "45 st                       1.0\n",
       "59 st                       6.0\n",
       "86 st                       3.0\n",
       "7 av                        1.0\n",
       "church av                   1.0\n",
       "cortelyou rd                1.0\n",
       "newkirk plaza               1.0\n",
       "50 st                       1.0\n",
       "8 av                        1.0\n",
       "marcy av                    1.0\n",
       "fulton st                   1.0\n",
       "forest av                   2.0\n",
       "knickerbocker av            1.0\n",
       "3 av                        1.0\n",
       "1 av                        1.0\n",
       "grand st                    1.0\n",
       "jefferson st                1.0\n",
       "franklin av                 4.0\n",
       "125 st                      3.0\n",
       "96 st                       5.0\n",
       "72 st                       3.0\n",
       "14 st                       3.0\n",
       "spring st                   1.0\n",
       "utica av                    1.0\n",
       "fordham rd                  1.0\n",
       "57 st                       2.0\n",
       "carroll st                  1.0\n",
       "4 av                        2.0\n",
       "jackson hts roosevelt av    2.0\n",
       "steinway st                 2.0\n",
       "queens plaza                1.0\n",
       "cathedral pkwy              1.0\n",
       "houston st                  1.0\n",
       "nevins st                   1.0\n",
       "grand army plaza            2.0\n",
       "president st                1.0\n",
       "110 st                      2.0\n",
       "grand central 42 st         1.0\n",
       "astor pl                    1.0\n",
       "bowling green               1.0\n",
       "flushing main st            3.0\n",
       "queensboro plaza            1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_stations = pd.Series(stationSightings)\n",
    "frequent_stations[frequent_stations == 0] = np.nan\n",
    "frequent_stations.dropna(inplace = True)\n",
    "frequent_stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- creating filter (letting users choose things)\n",
    "- pie chart of sightings per week\n",
    "- try named entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
